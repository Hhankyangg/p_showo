{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arc/miniconda3/envs/showo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-04 18:31:46,622] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arc/miniconda3/envs/showo/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible\n"
     ]
    }
   ],
   "source": [
    "from pdata import PersonalizedMMUDataset, PersonalizedT2IDataset, get_personalized_mmu_dataloader, get_personalized_t2i_dataloader\n",
    "from lightning.pytorch.utilities import CombinedLoader\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from models import Showo, MAGVITv2, get_mask_chedule\n",
    "from training.prompting_utils import UniversalPrompting, create_attention_mask_predict_next, create_attention_mask_for_mmu\n",
    "from training.utils import get_config, flatten_omega_conf, mask_or_random_replace_tokens, AverageMeter\n",
    "from transformers import AutoTokenizer\n",
    "from models.clip_encoder import CLIPVisionTower\n",
    "from transformers import CLIPImageProcessor\n",
    "from llava.llava import conversation as conversation_lib\n",
    "\n",
    "conversation_lib.default_conversation = conversation_lib.conv_templates[\"phi1.5\"]\n",
    "\n",
    "import os\n",
    "from omegaconf import DictConfig, ListConfig, OmegaConf\n",
    "config = OmegaConf.load('configs/showo_demo.yaml')\n",
    "# device setup\n",
    "device = torch.device(\"cuda:7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 13, 16, 16) = 3328 dimensions.\n",
      "Look-up free quantizer with codebook size: 8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'mask_token_id': 58497} were passed to Showo, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "/home/arc/Show-o/models/modeling_showo.py:49: FutureWarning: Accessing config attribute `w_clip_vit` directly via 'Showo' object attribute is deprecated. Please access 'w_clip_vit' over 'Showo's config object instead, e.g. 'unet.config.w_clip_vit'.\n",
      "  if self.w_clip_vit:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention implementation:  sdpa\n"
     ]
    }
   ],
   "source": [
    "# show o tokenizer setup and adding special tokens to universal prompting\n",
    "# llm model : 'microsoft/phi-1_5'\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model.showo.llm_model_path, padding_side =\"left\")\n",
    "uni_prompting = UniversalPrompting(tokenizer, max_text_len=config.dataset.preprocessing.max_seq_length,\n",
    "                                       special_tokens=(\"<|soi|>\", \"<|eoi|>\", \"<|sov|>\", \"<|eov|>\", \"<|t2i|>\", \"<|mmu|>\", \"<|t2v|>\", \"<|v2v|>\", \"<|lvg|>\"),\n",
    "                                       ignore_id=-100, cond_dropout_prob=config.training.cond_dropout_prob)\n",
    "\n",
    "# setting up the magvit-v2, for t2i\n",
    "vq_model = MAGVITv2.from_pretrained(config.model.vq_model.vq_model_name).to(device)\n",
    "# vq_model.requires_grad_(False)\n",
    "# vq_model.eval()\n",
    "\n",
    "# setting up vision tower: clip-vit only for mmu\n",
    "# vision_tower_name =config.clip_path\n",
    "# vision_tower = CLIPVisionTower(vision_tower_name).to(device)\n",
    "# clip_image_processor = CLIPImageProcessor.from_pretrained(vision_tower_name)\n",
    "\n",
    "# setting up the showo model \n",
    "model = Showo.from_pretrained(config.model.showo.pretrained_model_path).to(device)\n",
    "# model.eval()\n",
    "\n",
    "# setting up the parameters\n",
    "temperature = 0.8  # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 1  # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "# LLAVA_SYSTEM_PROMPT = \"A chat between a curious user and an artificial intelligence assistant. \" \\\n",
    "#                 \"The assistant gives helpful, detailed, and polite answers to the user's questions.\"\n",
    "# LLAVA_SYSTEM_PROMPT_LEN = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([58498])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(model.showo.get_input_embeddings())\n",
    "model.showo.get_input_embeddings().num_embeddings\n",
    "model.showo.get_input_embeddings().num_embeddings - len(tokenizer)\n",
    "model.showo.get_input_embeddings().weight.data.shape\n",
    "model.showo.lm_head.weight.shape\n",
    "model.showo.lm_head.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/home/arc/full_mcdata\"\n",
    "concept = \"dunpai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新 token ID: [50305, 50306, 50307, 50308, 50309, 50310, 50311, 50312, 50313, 50314, 50315, 50316, 50317, 50318, 50319, 50320, 50321]\n",
      "新增文本 token ID: [50305, 50306, 50307, 50308, 50309, 50310, 50311, 50312, 50313, 50314, 50315, 50316, 50317, 50318, 50319, 50320, 50321]\n",
      "Concept Token '<dunpai>' 的新 ID: 50305\n",
      "嵌入层大小: torch.Size([58515, 2048])\n",
      "index_no_updates 中 False 的位置: tensor([50305, 50306, 50307, 50308, 50309, 50310, 50311, 50312, 50313, 50314,\n",
      "        50315, 50316, 50317, 50318, 50319, 50320, 50321])\n",
      "index_no_updates 中 True 的数量: tensor(58498)\n"
     ]
    }
   ],
   "source": [
    "nums_new_token_i = 16\n",
    "\n",
    "#################################\n",
    "new_tokens = [f\"<{concept}>\"] + [f\"<token_{i}>\" for i in range(nums_new_token_i)]\n",
    "num_new_tokens = len(new_tokens)  # 17\n",
    "\n",
    "# 已知的原始参数\n",
    "# 文本 token 数量（ID 0-50304）\n",
    "original_text_vocab_size = len(tokenizer)  \n",
    "# Image token 数量（原 ID 50305-58497）\n",
    "original_image_vocab_size = model.showo.get_input_embeddings().num_embeddings - len(tokenizer)\n",
    "\n",
    "original_total_vocab = original_text_vocab_size + original_image_vocab_size  # 58498\n",
    "\n",
    "# 新的参数\n",
    "new_text_vocab_size = original_text_vocab_size + num_new_tokens  # 50305 + 17 = 50322\n",
    "new_total_vocab = original_total_vocab + num_new_tokens          # 58498 + 17 = 58515\n",
    "\n",
    "# ------------------------------\n",
    "# Step 1: 修改 Tokenizer 的词汇表\n",
    "# ------------------------------\n",
    "\n",
    "# 添加新 token 到 50305-50321 的位置\n",
    "num_new_tokens = tokenizer.add_tokens(new_tokens)\n",
    "new_token_ids = tokenizer.convert_tokens_to_ids(new_tokens)\n",
    "print(\"新 token ID:\", new_token_ids)  # 应输出 50305-50321\n",
    "\n",
    "# ------------------------------\n",
    "# Step 2: 调整模型的权重\n",
    "# ------------------------------\n",
    "with torch.no_grad():\n",
    "    # 获取嵌入层权重\n",
    "    embeddings = model.showo.get_input_embeddings().weight.data\n",
    "    \n",
    "    # 扩展嵌入层（58498 -> 58515）\n",
    "    model.showo.resize_token_embeddings(new_total_vocab)\n",
    "    # new_embeddings = model.showo.get_input_embeddings().weight.data\n",
    "\n",
    "    # 将原 Image Token 权重后移 17 位\n",
    "    original_image_weights = embeddings[original_text_vocab_size:original_total_vocab].clone()\n",
    "    model.showo.get_input_embeddings().weight.data[new_text_vocab_size:new_total_vocab] = original_image_weights\n",
    "    \n",
    "    # 初始化新 token 的权重（用原文本最后 17 个 token）\n",
    "    new_text_weights = embeddings[original_text_vocab_size - num_new_tokens : original_text_vocab_size].clone()\n",
    "    model.showo.get_input_embeddings().weight.data[original_text_vocab_size : new_text_vocab_size] = new_text_weights\n",
    "    # print(model.showo.lm_head.weight.data.shape[1])\n",
    "    # 处理 lm_head（假设与嵌入层共享权重）\n",
    "    if model.showo.lm_head.weight.data.shape[0] == new_total_vocab:\n",
    "        # 扩展 lm_head 权重\n",
    "        lm_head = model.showo.lm_head\n",
    "        new_lm_head = torch.nn.Linear(\n",
    "            lm_head.in_features, \n",
    "            new_total_vocab, \n",
    "            bias=hasattr(lm_head, 'bias')\n",
    "        )\n",
    "        new_lm_head.weight.data = lm_head.weight.data.clone()\n",
    "        new_lm_head.weight.data[new_text_vocab_size:new_total_vocab] = lm_head.weight.data[original_text_vocab_size:original_total_vocab]\n",
    "        new_lm_head.weight.data[original_text_vocab_size:new_text_vocab_size] = lm_head.weight.data[original_text_vocab_size - num_new_tokens : original_text_vocab_size]\n",
    "        if hasattr(lm_head, 'bias'):\n",
    "            new_lm_head.bias.data = lm_head.bias.data.clone()\n",
    "            new_lm_head.bias.data[new_text_vocab_size:new_total_vocab] = lm_head.bias.data[original_text_vocab_size:original_total_vocab]\n",
    "            new_lm_head.bias.data[original_text_vocab_size:new_text_vocab_size] = lm_head.bias.data[original_text_vocab_size - num_new_tokens : original_text_vocab_size]\n",
    "        \n",
    "        model.showo.lm_head = new_lm_head\n",
    "    else:\n",
    "        raise ValueError(\"lm_head weights do not match the input embeddings!\")\n",
    "\n",
    "index_no_updates = torch.ones((new_total_vocab,), dtype=torch.bool)\n",
    "index_no_updates[new_token_ids] = False\n",
    "# ------------------------------\n",
    "# 验证\n",
    "# ------------------------------\n",
    "# 检查新 token 的 ID\n",
    "print(\"新增文本 token ID:\", [tokenizer.convert_tokens_to_ids(t) for t in new_tokens])  # 应输出 50305-50321\n",
    "\n",
    "# 检查一个原 Image Token 的新 ID\n",
    "sample_image_token = tokenizer.convert_ids_to_tokens(original_text_vocab_size)  # 原 ID 50305\n",
    "print(f\"Concept Token '{sample_image_token}' 的新 ID:\", tokenizer.convert_tokens_to_ids(sample_image_token))  # 应输出 50322\n",
    "\n",
    "# 检查嵌入层形状\n",
    "print(\"嵌入层大小:\", model.showo.get_input_embeddings().weight.shape)  # 应显示 torch.Size([58515, 2048])\n",
    "\n",
    "# 检查 index_no_updates 中 True 的位置和数量，True 应该是 new token ids\n",
    "print(\"index_no_updates 中 False 的位置:\", torch.nonzero(~index_no_updates).squeeze())  # 应输出 50305-50321\n",
    "print(\"index_no_updates 中 True 的数量:\", torch.sum(index_no_updates))  # 应输出 58498\n",
    "\n",
    "with torch.no_grad():\n",
    "    orig_embeds = model.showo.get_input_embeddings().weight.data.clone()\n",
    "    orig_lm_head_weight = model.showo.lm_head.weight.data.clone()\n",
    "    orig_lm_head_bias = model.showo.lm_head.bias.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<|soi|>': tensor([50296]),\n",
       " '<|eoi|>': tensor([50297]),\n",
       " '<|sov|>': tensor([50298]),\n",
       " '<|eov|>': tensor([50299]),\n",
       " '<|t2i|>': tensor([50300]),\n",
       " '<|mmu|>': tensor([50301]),\n",
       " '<|t2v|>': tensor([50302]),\n",
       " '<|v2v|>': tensor([50303]),\n",
       " '<|lvg|>': tensor([50304]),\n",
       " '<|sot|>': tensor([50256]),\n",
       " '<|eot|>': tensor([50256]),\n",
       " '<|pad|>': tensor([50295])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_prompting.sptids_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showo.model.embed_tokens.weight requires_grad\n",
      "showo.lm_head.weight requires_grad\n",
      "showo.lm_head.bias requires_grad\n"
     ]
    }
   ],
   "source": [
    "vq_model.requires_grad_ = False\n",
    "vq_model.eval()\n",
    "model.train()\n",
    "for names, p in model.named_parameters():\n",
    "    if \"embed_tokens\" not in names and \"lm_head\" not in names:\n",
    "        p.requires_grad = False\n",
    "    else:\n",
    "        p.requires_grad = True\n",
    "\n",
    "trainable_params = [model.showo.get_input_embeddings().weight, model.showo.lm_head.weight, model.showo.lm_head.bias]\n",
    "optimizer = torch.optim.AdamW(\n",
    "            trainable_params, # for optimize the embeddings and the head\n",
    "            lr=1e-2,\n",
    "            betas=(0.9, 0.999),\n",
    "            weight_decay=1e-2,\n",
    "            eps=1e-08,\n",
    "        )\n",
    "for names, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        print(f\"{names} requires_grad\") # embed_token, lm_head会更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1278625/1029868437.py:2: FutureWarning: Accessing config attribute `mask_token_id` directly via 'Showo' object attribute is deprecated. Please access 'mask_token_id' over 'Showo's config object instead, e.g. 'unet.config.mask_token_id'.\n",
      "  mask_id = model.mask_token_id\n"
     ]
    }
   ],
   "source": [
    "mask_schedule = get_mask_chedule(config.training.get(\"mask_schedule\", \"cosine\"))\n",
    "mask_id = model.mask_token_id\n",
    "mask_dtype = model.showo.model.embed_tokens.weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting llava instruction data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# t2i_dataset = PersonalizedT2IDataset(data_root, concept)\n",
    "# t2i_dataloader = DataLoader(t2i_dataset, batch_size=5, shuffle=True, num_workers=10, pin_memory=True)\n",
    "mmu_dataloader = get_personalized_mmu_dataloader(data_root, concept, tokenizer, batch_size=5, num_workers=0, max_length=128)\n",
    "t2i_dataloader = get_personalized_t2i_dataloader(data_root, concept, tokenizer, batch_size=5, num_workers=0, max_length=128)\n",
    "\n",
    "\n",
    "iterables = {\n",
    "    'mmu_flow': mmu_dataloader,\n",
    "    't2i_flow': t2i_dataloader\n",
    "}\n",
    "\n",
    "\n",
    "combined_dataloader = CombinedLoader(iterables, mode=\"max_size_cycle\")\n",
    "\n",
    "# Before adding the new tokens, the vocab size is 58498\n",
    "# vocab size = 58498 = 50295  llm vocabsize\n",
    "#                    + 10     <|soi|> <|eoi|> <|sov|> <|eov|> <|t2i|> <|mmu|> <|t2v|> <|v2v|> <|lvg|> <|pad|>\n",
    "#                    + 8192   vq model codebook size\n",
    "#                    + 1      mask token (token id == 58497)\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "uni_prompting.sptids_dict\n",
    "# {'<|soi|>': tensor([50296]),\n",
    "#  '<|eoi|>': tensor([50297]),\n",
    "#  '<|sov|>': tensor([50298]),\n",
    "#  '<|eov|>': tensor([50299]),\n",
    "#  '<|t2i|>': tensor([50300]),\n",
    "#  '<|mmu|>': tensor([50301]),\n",
    "#  '<|t2v|>': tensor([50302]),\n",
    "#  '<|v2v|>': tensor([50303]),\n",
    "#  '<|lvg|>': tensor([50304]),\n",
    "#  '<|sot|>': tensor([50256]),\n",
    "#  '<|eot|>': tensor([50256]),\n",
    "#  '<|pad|>': tensor([50295])}\n",
    "\n",
    "# uni_prompting.text_tokenizer == tokenizer\n",
    "def prepare_inputs_and_labels(\n",
    "        pixel_values_or_image_ids: Union[torch.FloatTensor, torch.LongTensor],\n",
    "        texts: Union[str, str],\n",
    "        min_masking_rate: float = 0.0,\n",
    "        is_train: bool = True,\n",
    "):\n",
    "\n",
    "    image_tokens = vq_model.get_code(pixel_values_or_image_ids)\n",
    "    image_tokens = image_tokens + len(uni_prompting.text_tokenizer)\n",
    "\n",
    "    # create MLM mask and labels\n",
    "    input_ids, labels, loss_weight, mask_prob = mask_or_random_replace_tokens(\n",
    "        image_tokens,\n",
    "        mask_id,\n",
    "        config,\n",
    "        mask_schedule=mask_schedule,\n",
    "        is_train=is_train,\n",
    "    )\n",
    "    input_ids, masks, labels = uni_prompting((texts, input_ids, labels), 't2i')\n",
    "\n",
    "    return input_ids, labels, mask_prob, image_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_combined_dataloader = list(combined_dataloader)\n",
    "one_batch_mmu = list_combined_dataloader[0][0]['mmu_flow']\n",
    "one_batch_t2i = list_combined_dataloader[0][0]['t2i_flow']\n",
    "\n",
    "# one_batch_mmu = next(iter(mmu_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:28<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 7.42177457225566, loss_t2i: 8.953611062497508, loss_mmu: 1.2944279726670713\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 6.626295547096097, loss_t2i: 7.999885296335026, loss_mmu: 1.1319361937289336\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 6.107476789124158, loss_t2i: 7.363431599675392, loss_mmu: 1.083656797603685\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 5.945915611422792, loss_t2i: 7.1792658397129605, loss_mmu: 1.0125141003910376\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 5.800265599270256, loss_t2i: 7.012139320373535, loss_mmu: 0.9527703918972794\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 5.576078487902271, loss_t2i: 6.74552617754255, loss_mmu: 0.8982872555450517\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss: 5.683408416047389, loss_t2i: 6.892803318646489, loss_mmu: 0.845828506107233\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss: 5.770050652173101, loss_t2i: 7.010568054354921, loss_mmu: 0.8079803698525136\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss: 5.880341695279491, loss_t2i: 7.158044766406624, loss_mmu: 0.7695289059561126\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss: 5.581008327250578, loss_t2i: 6.791729567002277, loss_mmu: 0.7381228831957798\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss: 5.746380849760406, loss_t2i: 7.005443611923529, loss_mmu: 0.7101292087107288\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 loss: 5.586092754286163, loss_t2i: 6.807965512178382, loss_mmu: 0.6986015451197721\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 loss: 5.578917498491248, loss_t2i: 6.793343349378937, loss_mmu: 0.7212135095377358\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 loss: 5.272494914580364, loss_t2i: 6.424329232196419, loss_mmu: 0.6651570854746566\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 loss: 5.512755447504472, loss_t2i: 6.730252212407637, loss_mmu: 0.6427677994479939\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 loss: 5.778004626838529, loss_t2i: 7.0554337404212175, loss_mmu: 0.6682877464562046\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 loss: 5.431083567288457, loss_t2i: 6.6346889417998645, loss_mmu: 0.6166616179505173\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 loss: 5.20013867592325, loss_t2i: 6.353850715014399, loss_mmu: 0.5852901227011973\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 loss: 5.325779978109866, loss_t2i: 6.509501758886843, loss_mmu: 0.5908922994015168\n",
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 loss: 5.28897145816258, loss_t2i: 6.460553801789576, loss_mmu: 0.6026416741767708\n",
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 loss: 5.161755556962928, loss_t2i: 6.3089103747387325, loss_mmu: 0.5731358259003989\n",
      "Epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 loss: 5.39027291414689, loss_t2i: 6.599544077503438, loss_mmu: 0.5531877048161565\n",
      "Epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 loss: 5.02228256147735, loss_t2i: 6.1404388583436305, loss_mmu: 0.5496569292581811\n",
      "Epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 loss: 4.782850888310646, loss_t2i: 5.846313593338947, loss_mmu: 0.5289996795508326\n",
      "Epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 loss: 5.532112136179087, loss_t2i: 6.784745279623538, loss_mmu: 0.5215791626548281\n",
      "Epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 loss: 5.104142845893393, loss_t2i: 6.249997241156442, loss_mmu: 0.5207248514099997\n",
      "Epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 loss: 5.267490586455987, loss_t2i: 6.44642481511953, loss_mmu: 0.5517531009961147\n",
      "Epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 loss: 5.4702416488102505, loss_t2i: 6.705808041047077, loss_mmu: 0.5279758408361551\n",
      "Epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 loss: 5.096083261528793, loss_t2i: 6.2449073207621675, loss_mmu: 0.5007866926643313\n",
      "Epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 4.986432639919982, loss_t2i: 6.107424380827923, loss_mmu: 0.5024653247424534\n",
      "Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 loss: 4.697487524577549, loss_t2i: 5.750976771724467, loss_mmu: 0.4835299893605466\n",
      "Epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 loss: 4.985864001877454, loss_t2i: 6.111887153314084, loss_mmu: 0.4817708995269269\n",
      "Epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 loss: 4.8310001747948785, loss_t2i: 5.922718926351898, loss_mmu: 0.46412474753297106\n",
      "Epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 loss: 4.956420662451763, loss_t2i: 6.0810732598207435, loss_mmu: 0.45780979606265926\n",
      "Epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 loss: 4.911873394129228, loss_t2i: 6.0274273473389295, loss_mmu: 0.4496574552387607\n",
      "Epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 loss: 4.7986326996161015, loss_t2i: 5.881988223718137, loss_mmu: 0.4652102207194786\n",
      "Epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 loss: 5.023519861454866, loss_t2i: 6.168167688408676, loss_mmu: 0.44492798222571\n",
      "Epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 loss: 4.904122162838371, loss_t2i: 6.021979755284835, loss_mmu: 0.4326912963724866\n",
      "Epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 loss: 5.147906215823427, loss_t2i: 6.327619713179919, loss_mmu: 0.42905166638748987\n",
      "Epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 loss: 5.111512008978396, loss_t2i: 6.280119185545007, loss_mmu: 0.4370830788904307\n",
      "Epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 loss: 4.962916982417204, loss_t2i: 6.099900707906606, loss_mmu: 0.4149817898109251\n",
      "Epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 loss: 4.824662442110022, loss_t2i: 5.927432872811142, loss_mmu: 0.41358012059817506\n",
      "Epoch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 loss: 4.871770450047085, loss_t2i: 5.986421565620267, loss_mmu: 0.4131657547336452\n",
      "Epoch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 loss: 4.761569835701767, loss_t2i: 5.849269798823765, loss_mmu: 0.4107695161840137\n",
      "Epoch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 loss: 4.97635513909009, loss_t2i: 6.117890304448653, loss_mmu: 0.41021399344412646\n",
      "Epoch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 loss: 4.734630672299132, loss_t2i: 5.814119168690273, loss_mmu: 0.41667636073365505\n",
      "Epoch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 loss: 4.77523946762085, loss_t2i: 5.863052421686601, loss_mmu: 0.42398709636561727\n",
      "Epoch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 loss: 4.56616168606038, loss_t2i: 5.6045852923879815, loss_mmu: 0.41246664227575675\n",
      "Epoch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 loss: 5.169183648362452, loss_t2i: 6.361976205086221, loss_mmu: 0.398013097519169\n",
      "Epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 loss: 4.536058114499462, loss_t2i: 5.569990488947655, loss_mmu: 0.40032825801445515\n",
      "Epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 loss: 4.921446634798634, loss_t2i: 6.052781280206174, loss_mmu: 0.3961076393571435\n",
      "Epoch 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 loss: 4.94081998844536, loss_t2i: 6.0795356546129495, loss_mmu: 0.3859569726093691\n",
      "Epoch 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 loss: 4.815396153196996, loss_t2i: 5.923952409199306, loss_mmu: 0.38117062665370044\n",
      "Epoch 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 loss: 4.8338497901449395, loss_t2i: 5.9474581553011525, loss_mmu: 0.3794160808379553\n",
      "Epoch 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 loss: 4.710834858368854, loss_t2i: 5.79451507451583, loss_mmu: 0.37611351952869065\n",
      "Epoch 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 loss: 4.76106503058453, loss_t2i: 5.858552572678547, loss_mmu: 0.371114543430051\n",
      "Epoch 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 loss: 4.478070220168756, loss_t2i: 5.504282469652137, loss_mmu: 0.3732208450685959\n",
      "Epoch 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 loss: 4.810152409028034, loss_t2i: 5.919104814529419, loss_mmu: 0.37434219257259854\n",
      "Epoch 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 loss: 4.727627294404166, loss_t2i: 5.816508986512009, loss_mmu: 0.37210016005805563\n",
      "Epoch 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 loss: 4.60643356187003, loss_t2i: 5.667305746857001, loss_mmu: 0.36294434957054195\n",
      "Epoch 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 loss: 4.438920310565403, loss_t2i: 5.458986160706501, loss_mmu: 0.35865633307519007\n",
      "Epoch 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 loss: 4.572150459094924, loss_t2i: 5.625573046353399, loss_mmu: 0.35845979067439937\n",
      "Epoch 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 loss: 4.94317795305836, loss_t2i: 6.088279091582006, loss_mmu: 0.3627732271442608\n",
      "Epoch 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 loss: 4.294743773888569, loss_t2i: 5.280028452678603, loss_mmu: 0.3536046597422386\n",
      "Epoch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 loss: 4.593328862774129, loss_t2i: 5.653890680293648, loss_mmu: 0.35108124502763455\n",
      "Epoch 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 loss: 4.697448501781541, loss_t2i: 5.783927859092246, loss_mmu: 0.3515307250983861\n",
      "Epoch 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 loss: 4.76004061893541, loss_t2i: 5.862751488782922, loss_mmu: 0.34919684745219287\n",
      "Epoch 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 loss: 4.815482957022531, loss_t2i: 5.932624330326003, loss_mmu: 0.3469172368320275\n",
      "Epoch 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 loss: 4.666931921122026, loss_t2i: 5.747735763082699, loss_mmu: 0.3437162933453005\n",
      "Epoch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 loss: 4.513328250573606, loss_t2i: 5.556664787993139, loss_mmu: 0.33998184453467933\n",
      "Epoch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 loss: 4.624139484094114, loss_t2i: 5.695582204935502, loss_mmu: 0.3383681932274176\n",
      "Epoch 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 loss: 4.49113543666139, loss_t2i: 5.529593686668241, loss_mmu: 0.33730206212827135\n",
      "Epoch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 loss: 4.265298699846073, loss_t2i: 5.247157057937311, loss_mmu: 0.337864776807172\n",
      "Epoch 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 loss: 4.6437845205774115, loss_t2i: 5.721313902309963, loss_mmu: 0.33366657101682257\n",
      "Epoch 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 loss: 4.5015217698350245, loss_t2i: 5.543292918983771, loss_mmu: 0.3344368308174367\n",
      "Epoch 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 loss: 4.047284688268389, loss_t2i: 4.97664306115131, loss_mmu: 0.32985081614888445\n",
      "Epoch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:25<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 loss: 4.541884750736003, loss_t2i: 5.593594857624599, loss_mmu: 0.3350440637797725\n",
      "Epoch 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:25<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 loss: 4.418182908272256, loss_t2i: 5.440972089767456, loss_mmu: 0.3270257309991486\n",
      "Epoch 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:25<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 loss: 4.781453541346958, loss_t2i: 5.894612541004103, loss_mmu: 0.32881719284519856\n",
      "Epoch 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 loss: 4.415105325835092, loss_t2i: 5.436251839812921, loss_mmu: 0.330518835053152\n",
      "Epoch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 loss: 4.443418590389952, loss_t2i: 5.47255958586323, loss_mmu: 0.326854352022008\n",
      "Epoch 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 loss: 4.406244577193747, loss_t2i: 5.424393344898613, loss_mmu: 0.33364905561415514\n",
      "Epoch 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 loss: 4.633331796344446, loss_t2i: 5.709937392448892, loss_mmu: 0.32690890817617885\n",
      "Epoch 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 loss: 4.518559356125033, loss_t2i: 5.5662966942300605, loss_mmu: 0.3276095322656388\n",
      "Epoch 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 loss: 4.278078366299065, loss_t2i: 5.26545022215162, loss_mmu: 0.32859066364412404\n",
      "Epoch 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 loss: 4.550484744869933, loss_t2i: 5.606214859047714, loss_mmu: 0.32756379581227596\n",
      "Epoch 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 loss: 4.619091158010522, loss_t2i: 5.693014261673908, loss_mmu: 0.3233983812435549\n",
      "Epoch 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 loss: 4.3964575626412215, loss_t2i: 5.414811212189344, loss_mmu: 0.323042630236976\n",
      "Epoch 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 loss: 4.675721037144563, loss_t2i: 5.763980515149175, loss_mmu: 0.3226828175996031\n",
      "Epoch 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 loss: 4.589533197636507, loss_t2i: 5.658124456600267, loss_mmu: 0.31516770554744467\n",
      "Epoch 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 loss: 4.10764970098223, loss_t2i: 5.054940846501564, loss_mmu: 0.3184846647235812\n",
      "Epoch 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 loss: 4.319661617279053, loss_t2i: 5.321067588669913, loss_mmu: 0.3140374291688204\n",
      "Epoch 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 loss: 4.50840767792293, loss_t2i: 5.557981821955467, loss_mmu: 0.3101107891725034\n",
      "Epoch 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 loss: 4.640713346247771, loss_t2i: 5.722834752530468, loss_mmu: 0.3122273313679865\n",
      "Epoch 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 loss: 4.315993566902316, loss_t2i: 5.316696483261731, loss_mmu: 0.31318148236949833\n",
      "Epoch 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 loss: 4.419954796226657, loss_t2i: 5.446438108171735, loss_mmu: 0.3140210105220274\n",
      "Epoch 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 loss: 4.566065121670158, loss_t2i: 5.630015694365209, loss_mmu: 0.3102625949042184\n",
      "Epoch 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 loss: 4.3650728877709835, loss_t2i: 5.378911261655847, loss_mmu: 0.30971904068577044\n",
      "Epoch 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 loss: 4.578340861262108, loss_t2i: 5.645318262431086, loss_mmu: 0.31043085246822055\n",
      "Epoch 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 loss: 4.276808767902608, loss_t2i: 5.268557061954421, loss_mmu: 0.30981513105180797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.output_size = new_total_vocab\n",
    "for epoch in range(0, 100):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    loss_list = []\n",
    "    loss_t2i_list = []\n",
    "    loss_mmu_list = []\n",
    "    for batch, batch_idx, dataloader_idx in tqdm(list_combined_dataloader):\n",
    "        batch_size_mmu = batch[\"mmu_flow\"][\"images\"].shape[0]\n",
    "        batch_size_t2i = batch[\"t2i_flow\"][\"images\"].shape[0]\n",
    "        \n",
    "        # t2i format\n",
    "        pixel_values, texts = batch[\"t2i_flow\"][\"images\"], batch[\"t2i_flow\"][\"conditions\"]\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        input_ids, labels, mask_prob, image_tokens_ori = prepare_inputs_and_labels(pixel_values, texts, is_train=True)\n",
    "        attention_mask = create_attention_mask_predict_next(input_ids,\n",
    "                                                                pad_id=int(uni_prompting.sptids_dict['<|pad|>']),\n",
    "                                                                soi_id=int(uni_prompting.sptids_dict['<|soi|>']),\n",
    "                                                                eoi_id=int(uni_prompting.sptids_dict['<|eoi|>']),\n",
    "                                                                rm_pad_in_image=True,\n",
    "                                                                return_inverse_mask=True)\n",
    "        attention_mask = attention_mask.to(mask_dtype)\n",
    "        \n",
    "        # mmu format\n",
    "        pixel_values_mmu, input_ids_mmu, labels_mmu = (batch[\"mmu_flow\"][\"images\"],\n",
    "                                                      batch[\"mmu_flow\"][\"input_ids\"],\n",
    "                                                      batch[\"mmu_flow\"][\"labels\"])\n",
    "        pixel_values_mmu = pixel_values_mmu.to(device, non_blocking=True)\n",
    "        input_ids_mmu = input_ids_mmu.to(device, non_blocking=True)\n",
    "        image_tokens_mmu = vq_model.get_code(pixel_values_mmu)\n",
    "        image_tokens_mmu = image_tokens_mmu + len(uni_prompting.text_tokenizer)\n",
    "        \n",
    "        input_ids_mmu = torch.cat([\n",
    "                    (torch.ones(input_ids_mmu.shape[0], 1) * uni_prompting.sptids_dict['<|mmu|>']).to(\n",
    "                        device),\n",
    "                    (torch.ones(input_ids_mmu.shape[0], 1) * uni_prompting.sptids_dict['<|soi|>']).to(\n",
    "                        device),\n",
    "                    image_tokens_mmu,\n",
    "                    (torch.ones(input_ids_mmu.shape[0], 1) * uni_prompting.sptids_dict['<|eoi|>']).to(\n",
    "                        device),\n",
    "                    input_ids_mmu,\n",
    "                ], dim=1).long()\n",
    "\n",
    "        labels_mmu = torch.cat([\n",
    "                    (torch.ones(input_ids_mmu.shape[0], 1) * uni_prompting.ignore_id).to(device),\n",
    "                    (torch.ones(input_ids_mmu.shape[0], 1) * uni_prompting.ignore_id).to(device),\n",
    "                    torch.ones_like(image_tokens_mmu) * uni_prompting.ignore_id,\n",
    "                    (torch.ones(input_ids_mmu.shape[0], 1) * uni_prompting.ignore_id).to(device),\n",
    "                    labels_mmu.to(device)\n",
    "                ], dim=1).long()\n",
    "        \n",
    "        \n",
    "        attention_mask_mmu = create_attention_mask_for_mmu(input_ids_mmu.to(input_ids.device),\n",
    "                                                               eoi_id=int(uni_prompting.sptids_dict['<|eoi|>']))\n",
    "        attention_mask_mmu = attention_mask_mmu.to(mask_dtype)\n",
    "        attention_mask = torch.cat([attention_mask, attention_mask_mmu], dim=0)\n",
    "        input_ids = torch.cat((input_ids, input_ids_mmu.to(input_ids.device)), dim=0)\n",
    "        labels = torch.cat((labels, labels_mmu.to(input_ids.device)), dim=0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits, loss_t2i, loss_lm, loss_mmu = model(\n",
    "                    input_ids=input_ids,\n",
    "                    input_embeddings=None,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels,\n",
    "                    label_smoothing=0.0,\n",
    "                    batch_size_t2i=batch_size_t2i,\n",
    "                    batch_size_lm=0,\n",
    "                    batch_size_mmu=batch_size_mmu,\n",
    "                    max_seq_length=128,\n",
    "                )\n",
    "        loss = 0.8 * loss_t2i + 0.2 * loss_mmu\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "        loss_t2i_list.append(loss_t2i.item())\n",
    "        loss_mmu_list.append(loss_mmu.item())\n",
    "        # tqdm.set_postfix(loss=loss.item(), loss_t2i=loss_t2i.item(), loss_mmu=loss_mmu.item())\n",
    "        # tqdm.write(f\"loss: {loss.item()}, loss_t2i: {loss_t2i.item()}, loss_mmu: {loss_mmu.item()}\")\n",
    "        # 恢复原始权重\n",
    "        with torch.no_grad():\n",
    "            model.showo.get_input_embeddings().weight.data[index_no_updates] = orig_embeds[index_no_updates]\n",
    "            model.showo.lm_head.weight.data[index_no_updates] = orig_lm_head_weight[index_no_updates]\n",
    "            model.showo.lm_head.bias.data[index_no_updates] = orig_lm_head_bias[index_no_updates]\n",
    "    print(f\"Epoch {epoch} loss: {np.mean(loss_list)}, loss_t2i: {np.mean(loss_t2i_list)}, loss_mmu: {np.mean(loss_mmu_list)}\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50301, 50296, 50424, 50872, 51385, 51136, 50904, 50617, 52184, 51160,\n",
       "        52201, 55256, 51161, 55191, 54775, 54521, 55265, 54745, 50940, 51326,\n",
       "        50361, 50425, 54282, 50616, 50693, 54285, 50696, 50644, 50793, 50793,\n",
       "        55400, 51160, 54680, 55257, 53000, 54266, 53434, 52915, 54007, 53498,\n",
       "        50425, 51214, 51208, 51716, 50440, 50661, 50648, 50661, 50665, 54745,\n",
       "        52914, 57539, 53191, 53451, 52930, 53962, 52942, 52918, 52986, 54278,\n",
       "        51144, 50438, 51188, 50376, 52130, 50646, 50868, 52674, 50831, 56715,\n",
       "        53765, 52738, 50498, 50371, 53938, 50563, 50946, 50930, 51938, 51187,\n",
       "        50898, 50851, 51380, 51915, 53434, 52523, 52411, 53939, 51401, 53683,\n",
       "        50329, 52382, 52915, 51363, 50846, 51350, 52435, 50342, 58049, 55858,\n",
       "        51610, 50498, 52890, 55492, 55162, 57550, 57645, 55678, 57633, 57612,\n",
       "        57732, 55793, 57868, 57788, 54390, 55508, 51860, 54089, 51353, 56126,\n",
       "        57689, 56021, 51416, 54329, 55499, 52473, 57702, 56985, 55897, 56161,\n",
       "        56534, 54882, 54567, 52818, 52263, 57955, 56419, 55421, 55202, 57130,\n",
       "        57673, 56911, 55431, 58274, 57263, 57926, 57689, 52055, 52505, 57150,\n",
       "        51422, 58216, 54617, 50649, 54537, 54970, 54988, 53928, 54747, 53593,\n",
       "        57716, 54745, 54942, 52124, 51634, 51530, 52774, 51526, 50983, 55774,\n",
       "        51034, 54454, 55516, 56067, 51873, 55126, 52246, 56282, 55145, 51986,\n",
       "        53674, 54006, 53578, 51946, 57699, 51431, 52633, 55324, 54711, 53553,\n",
       "        56561, 56102, 56238, 58217, 57047, 51686, 53538, 51566, 51490, 50536,\n",
       "        55963, 58423, 50399, 51753, 57931, 57511, 55017, 56168, 56171, 55470,\n",
       "        51564, 57090, 56198, 52516, 52106, 58146, 55782, 56414, 57234, 58490,\n",
       "        55692, 56166, 58129, 56169, 57224, 55927, 53615, 51919, 53988, 53412,\n",
       "        52054, 51434, 51495, 56177, 51498, 51095, 58271, 57890, 58354, 55767,\n",
       "        54129, 52895, 56589, 55255, 54006, 53542, 52519, 58470, 56623, 56624,\n",
       "        56718, 57982, 57714, 54166, 50342, 56677, 54798, 56704, 50297, 29904,\n",
       "           25, 10347,   345,  6216,   611,   428,   318,   220, 50305,   287,\n",
       "          262,  4590,    30, 24994,  8808,  8643,    25,   314,   460,  6216,\n",
       "          326,   428,   318,   407,   220, 50305,   287,   262,  4590,    13,\n",
       "        50256, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295,\n",
       "        50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295,\n",
       "        50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295,\n",
       "        50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295,\n",
       "        50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295,\n",
       "        50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295,\n",
       "        50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295, 50295],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "showo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
